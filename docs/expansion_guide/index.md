# テストラボシステムでの検証ガイド

## 目的

本ガイドでは、コンテナフォーマットへの対応に必要な要素を定義し、
テストラボシステムを活用して検証を行う方法についてガイドを示す。

## コンテナフォーマット対応の定義

コンテナフォーマットへの対応をするものとしてソフトウェア、ハードウェアなど考えられる。
コンテナフォーマットを処理する観点からは以下が考えられる。

- コンテナデータを入力に用いるシステム
- コンテナデータを出力に用いるシステム
- 上記の両方を行う

それぞれについての要件を以下に示す。

### コンテナデータを入力に用いるシステム

コンテナフォーマットを入力に用いるシステムとは以下の機能を実現することである。

1. コンテナデータからコンテナフォーマットの仕様に従い値を取り出す。
2. 取り出した値に従いリポジトリからスキーマファイルを取得する。
3. スキーマファイルを利用してコンテナデータを処理する。

上記の３機能を実現できればコンテナフォーマットを入力対応したソフトウェアシステムである。

### コンテナデータを出力に用いるシステム

コンテナフォーマットを出力に用いるシステムは以下の機能を実現することである。

1. ペイロードをコンテナフォーマットに従いコンテナデータを作成する。
2. コンテナデータに対応するスキーマファイルを定義する。
3. コンテナデータを出力（送信）する
 
## テストラボシステムでの検証ガイド

### テストラボシステムの構成
環境構築で示したように、テストラボシステムは、以下のような構成となっている。
![](./overview.drawio.png)

テストラボシステムは検証の目的のため以下の機能を有している。

- コンテナデータを入力に用いるソフトウェア
- コンテナデータを出力に用いるソフトウェア
- スキーマファイルのエディタ 兼 リポジトリサーバ

それぞれについて解説を行い、コンテナフォーマット対応を行うためのガイドを示す。

### コンテナを入力に使う事例

### コンテナを出力に使う事例

### スキーマファイルのエディタ 兼 リポジトリサーバ


<!-- ## コンテナフォーマットを取り扱うシステムの構成

環境構築で示したように、テストラボシステムは、以下のような構成となっている。
![](./overview.drawio.png)

コンテナフォーマットを取り扱うシステムの検証のためには以下の検討事項がある


## チュートリアルでの構成例

チュートリアルでの構成について、コンテナ処理データ蓄積部分を詳細化すると以下のような構成要素を持っている。

![](./detail.drawio.png)


テストラボシステムの構成要素について、以降に詳細を記述する。

### kafka
kafka はデータ構造に依存しないメッセージキューである。。
トピックと呼ばれる単位でキューを構成し、キューに対してデータを提供する処理と、キューからデータを取得する処理が存在する。
kafkaとは、このようなキューを提供するためのミドルウェアである。

### WebApp
WebAppはセンサデータを取得し、センサデータを格納したコンテナデータをhttp経由によって収集し、kafkaに投入するアプリである。  
コンテナデータはkafkaのキューに格納され、次の処理へ引き渡される。

### container-consumer
container-consumerはkafkaのキューからコンテナデータを取得し、処理するアプリである。
コンテナデータを解析して、対応するスキーマファイルをスキーマリポジトリから取得する。
スキーマファイルを利用して、コンテナデータを処理し利用しやすいフォーマットに変換し、kafkaに投入する。

### スキーマリポジトリ
コンテナに格納されたデータのスキーマを管理するリポジトリである。
スキーマファイルの定義をしておくことで、コンテナデータに対応するスキーマデータを配賦できる。

### KSQL
kafka のキューにあるデータに対して、Streaming SQLと呼ばれるストリームデータにSQLライクなクエリを利用可能にする仕組みである

kafkaのキューに格納されたデータをSQLライクなクエリで処理することができる。
処理方法の定義例は [環境構築手順](./environment#%E3%83%87%E3%83%BC%E3%82%BF%E5%A4%89%E6%8F%9B%E3%81%AE%E7%99%BB%E9%8C%B2) であり、
kafkaのキューに入るデータをストリーミングテーブルとして定義することや、ストリーミングテーブルのデータをkafkaのキューとして出力することができる。

ここでは、JSONのデータをAVROと呼ばれるデータフォーマットに書き換えることと、サーバでのタイムスタンプの付与を行う。

### JDBC Connector  
kafkaのキューにAVRO形式で蓄積したデータをRDBに蓄積するための仕組みである。 -->
